{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_csv = pd.read_csv(\"../data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_DIM = 384 # most images are already 384x384\n",
    "def pad_square(image):\n",
    "    old_size = image.size  # old_size[0] is in (width, height) format\n",
    "    ratio = float(IMAGE_DIM)/max(old_size)\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    "    im = image.resize(new_size, Image.ANTIALIAS)\n",
    "    # create a new image and paste the resized on it\n",
    "    new_im = Image.new(\"RGB\", (IMAGE_DIM, IMAGE_DIM))\n",
    "    new_im.paste(im, ((IMAGE_DIM-new_size[0])//2,\n",
    "                        (IMAGE_DIM-new_size[1])//2))\n",
    "    return new_im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt with Tensorflow - This actually works\n",
    "### Inception-v3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.python.platform\n",
    "from tensorflow.python.platform import gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# This cell REPLACES tif images with padded jpg images\n",
    "IMAGE_DIM = 384 # most images are already 384x384\n",
    "def create_padded_jpg(file_path):\n",
    "    image = Image.open(file_path)\n",
    "    old_size = image.size  # old_size[0] is in (width, height) format\n",
    "    ratio = float(IMAGE_DIM)/max(old_size)\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    "    im = image.resize(new_size, Image.ANTIALIAS)\n",
    "    # create a new image and paste the resized on it\n",
    "    new_im = Image.new(\"RGB\", (IMAGE_DIM, IMAGE_DIM))\n",
    "    new_im.paste(im, ((IMAGE_DIM-new_size[0])//2,\n",
    "                        (IMAGE_DIM-new_size[1])//2))\n",
    "    new_im.save(file_path.replace(\"tif\", \"jpg\"), \"jpeg\")\n",
    "\n",
    "for directory, subdirectories, files in os.walk(\"legs_folder_jpg\"):\n",
    "    for file in files:\n",
    "        path = os.path.join(directory, file)\n",
    "        if file.endswith(\".tif\"):\n",
    "            create_padded_jpg(path)\n",
    "            os.remove(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Vector extraction (produces list with vector per image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_graph():\n",
    "    with gfile.FastGFile('inception-2015-12-05/classify_image_graph_def.pb', 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    _ = tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "def extract_features(image):\n",
    "    nb_features = 2048\n",
    "    features = np.empty(nb_features)\n",
    "    labels = []\n",
    "\n",
    "    create_graph()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        next_to_last_tensor = sess.graph.get_tensor_by_name('pool_3:0')\n",
    "\n",
    "        image_data = gfile.FastGFile(image, 'rb').read()\n",
    "\n",
    "        predictions = sess.run(next_to_last_tensor, {'DecodeJpeg/contents:0': image_data})\n",
    "        return np.squeeze(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patient_ids = []\n",
    "dates = []\n",
    "feature_vects = []\n",
    "for directory, subdirectories, files in os.walk(\"legs_folder_jpg\"):\n",
    "    for file in files:\n",
    "        path = os.path.join(directory, file)\n",
    "        if path.endswith(\".jpg\"):\n",
    "            patient_ids.append(directory.split(\"/\")[1] + \"/\" + file.split(\".\")[0])\n",
    "            feature_vects.append(extract_features(path))\n",
    "            \n",
    "df = pd.DataFrame(feature_vects, index=patient_ids)\n",
    "pickle.dump(df, open(\"inception_cnn_features.pkl\", \"wb\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "test_patient_ids = ['2','32','24','24b','6','7', '41']\n",
    "# df contains extracted features from a CNN (with index <patient_id>/<scan_date>)\n",
    "# data filename contains scan pairing and class\n",
    "# feature combine type specifies how to combine features ('c' = concat, 'd' = difference)\n",
    "def produce_data(df, data_filename, feature_combine_type, augment = False, normalize=False):\n",
    "    input_csv = pd.read_csv(data_filename)\n",
    "\n",
    "    features = []\n",
    "    row_ids = []\n",
    "    Y = []\n",
    "    \n",
    "    if normalize:\n",
    "        x = df.values #returns a numpy array\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        x_scaled = min_max_scaler.fit_transform(x)\n",
    "        df = pd.DataFrame(x_scaled)\n",
    "\n",
    "    for index, row in input_csv.iterrows():\n",
    "        patient_id = str(row[\"patient_id\"])\n",
    "        scan_1 = os.path.join(patient_id, row[\"scan_1\"])\n",
    "        scan_2 = os.path.join(patient_id, row[\"scan_2\"])\n",
    "        row_id = patient_id + \"/\" + row[\"scan_1\"] + \"/\" + row[\"scan_2\"]\n",
    "        \n",
    "\n",
    "        if scan_1 not in df.index or scan_2 not in df.index:\n",
    "            continue\n",
    "\n",
    "        # Skip if either scan is not found\n",
    "        v1 = df.loc[scan_1]\n",
    "        v2 = df.loc[scan_2]\n",
    "\n",
    "        Y.append(row[\"y\"])\n",
    "        \n",
    "        augment_sample = (augment and patient_id not in test_patient_ids and not row[\"y\"] == 'S')\n",
    "        row_ids.append(row_id)\n",
    "        if augment_sample:\n",
    "            row_ids.append(patient_id + \"/\" + row[\"scan_2\"] + \"/\" + row[\"scan_1\"])\n",
    "            if row[\"y\"] == 'I':\n",
    "                Y.append('R')\n",
    "            elif row[\"y\"] == 'R':\n",
    "                Y.append('I')\n",
    "\n",
    "        if feature_combine_type == 'c':\n",
    "            features.append(v1 + v2)\n",
    "            if augment_sample:\n",
    "                features.append(v2 + v1)\n",
    "        elif feature_combine_type == 'd':\n",
    "            features.append(np.subtract(v1,v2))\n",
    "            if augment_sample:\n",
    "                features.append(np.subtract(v2,v1))\n",
    "\n",
    "    df = pd.DataFrame(features, index=row_ids)\n",
    "    df[\"y\"] = Y\n",
    "\n",
    "    print(df.shape)\n",
    "    return df.loc[:, (df != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 2049)\n"
     ]
    }
   ],
   "source": [
    "# THIS PRODUCES A FEATURE SET BY CONCATENATING FEATURE VECTORS\n",
    "inception_df = pd.read_pickle(\"inception_cnn_features.pkl\")\n",
    "data2 = produce_data(inception_df, \"../data.csv\", 'c')\n",
    "pickle.dump(data2, open(\"data_inception_cnn.pkl\", \"wb\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 2049)\n"
     ]
    }
   ],
   "source": [
    "# THIS PRODUCES A FEATURE SET BY DIFFERENCING FEATURE VECTORS\n",
    "inception_df = pd.read_pickle(\"inception_cnn_features.pkl\")\n",
    "data3 = produce_data(inception_df, \"../data.csv\", 'd', normalize=False)\n",
    "pickle.dump(data3, open(\"data_inception_cnn_diff.pkl\", \"wb\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 396)\n"
     ]
    }
   ],
   "source": [
    "# Produce reduced dimension feature set\n",
    "vectors = pd.read_pickle(\"inception_cnn_features.pkl\")\n",
    "data4 = produce_data(vectors.loc[:, (vectors.std()**2) > .1], \"../data.csv\", 'd')\n",
    "pickle.dump(data4, open(\"data_inception_cnn_diff_reduced_dim.pkl\", \"wb\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89, 396)\n"
     ]
    }
   ],
   "source": [
    "# Produce reduced dimension feature set\n",
    "vectors = pd.read_pickle(\"inception_cnn_features.pkl\")\n",
    "data4 = produce_data(vectors.loc[:, (vectors.std()**2) > .1], \"../data.csv\", 'd', normalize=False, augment=True)\n",
    "pickle.dump(data4, open(\"data_inception_cnn_diff_reduced_dim_augmented.pkl\", \"wb\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
